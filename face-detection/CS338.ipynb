{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS338.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF3dqy7CVgmr",
        "outputId": "18f8ca0f-4d7f-43ff-bac0-6a8976761b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS338'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 49 (delta 5), reused 49 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/19521242bao/CS338.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CS338"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvvBcgK0WIsj",
        "outputId": "8c9c8e9d-59cf-4eb0-a581-8844e9164f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CS338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBEs4uwWTHV",
        "outputId": "cffab179-40c8-41be-b7dd-c4e51e1f0253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |▎                               | 20 kB 39.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 30 kB 42.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 40 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 51 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |▉                               | 61 kB 39.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 71 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 133 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 143 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 204 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 215 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 266 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 276 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 286 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 348 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 358 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 368 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 399 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 419 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 430 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 491 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 501 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 532 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 563 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 604 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 665 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 737 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 768 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 798 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 829 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 839 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 870 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 890 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 901 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 931 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 962 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 972 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.6 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3 MB 32.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mtcnn import MTCNN \n",
        "import cv2\n",
        "\n",
        "class Face_detector:\n",
        "    def  __init__(self) :\n",
        "        self.detector=MTCNN()\n",
        "    def detect(self,img):\n",
        "        result=self.detector.detect_faces(img)\n",
        "        if len(result)==0:\n",
        "            return None\n",
        "        bbox =result[0][\"box\"] # get bbox\n",
        "        x_min = bbox[0]\n",
        "        y_min = bbox[1]\n",
        "        x_max = bbox[0] + bbox[2]\n",
        "        y_max = bbox[1] + bbox[3]\n",
        "\n",
        "        return (x_min, y_min, x_max, y_max)"
      ],
      "metadata": {
        "id": "y8TD2GtmWR1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-vggface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zurtvjqW8Va",
        "outputId": "d87607fb-608b-4e21-e9a1-8b749caa4683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-vggface\n",
            "  Downloading keras_vggface-0.6-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (7.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-vggface) (1.5.2)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rcfdm3hXEt-",
        "outputId": "93d40360-6b66-44b0-9417-6afe5188f570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2 \n",
        "from skimage.feature import hog\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.applications import xception\n",
        "import numpy as np\n",
        "from tensorflow import keras \n",
        "\n",
        "\n",
        "\n",
        "# !pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "# !pip install keras_applications --no-deps\n",
        "filename =r'/usr/local/lib/python3.7/dist-packages/keras_vggface/models.py'\n",
        "text = open(filename).read()\n",
        "open(filename, \"w+\").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface import utils\n",
        "\n",
        "vggface = VGGFace(model='resnet50') # or VGGFace() as default\n",
        "class VGG16_FE:\n",
        "\n",
        "    def __init__(self):\n",
        "        base_model = VGG16(weights='imagenet')\n",
        "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
        "\n",
        "    def extract(self, img ):\n",
        "        img = img.resize( (224, 224))\n",
        "        img=img.convert('RGB')\n",
        "        img_data = image.img_to_array(img)\n",
        "        img_data = np.expand_dims(img_data, axis=0)\n",
        "        img_data = preprocess_input(img_data)\n",
        "\n",
        "        feature = self.model.predict(img_data)[0]\n",
        "\n",
        "        return feature/np.linalg.norm(feature)\n",
        "\n",
        "class Xception_FE:\n",
        "    def __init__(self):\n",
        "        base_model = xception.Xception(weights='imagenet')\n",
        "        self.model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
        "\n",
        "    def extract(self, img):\n",
        "        img = img.resize((299, 299))\n",
        "        img = img.convert('RGB')\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = xception.preprocess_input(x)\n",
        "        feature = self.model.predict(x)[0]\n",
        "        feature = feature / np.linalg.norm(feature)\n",
        "\n",
        "        return feature\n",
        "class VGGFACE_FE:\n",
        "    def __init__(self):\n",
        "        self.model = VGGFace(model='vgg16', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "    def extract(self, img):\n",
        "        img = img.resize((224, 224))\n",
        "        img = img.convert('RGB')\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = utils.preprocess_input(x, version=1)\n",
        "        feature = self.model.predict(x)[0]\n",
        "        feature = feature / np.linalg.norm(feature)\n",
        "\n",
        "        return feature"
      ],
      "metadata": {
        "id": "vP131gc-WjVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c68b951-26eb-4ef2-b6e1-8094f349d2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_resnet50.h5\n",
            "165445632/165439116 [==============================] - 1s 0us/step\n",
            "165453824/165439116 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "///////////////////////////////////////////////////\n",
        "from multiprocessing import process\n",
        "import os\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy import spatial\n",
        "import time\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from google.colab.patches import cv2_imshow\n",
        "# import feature_extractor\n",
        "# import face_detector\n",
        "\n",
        "class Facesystem:\n",
        "    def __init__(self,dataset_path,extractor_method):\n",
        "        if extractor_method==\"VGG\":\n",
        "            self.extractor=VGG16_FE()\n",
        "        elif extractor_method==\"Xception\":\n",
        "            self.extractor=Xception_FE()\n",
        "        elif extractor_method==\"VGGFACE\":\n",
        "            self.extractor=VGGFACE_FE()\n",
        "        self.detector=Face_detector()\n",
        "        self.dataset_path = dataset_path\n",
        "        if not os.path.exists(self.dataset_path):\n",
        "            os.mkdir(self.dataset_path)\n",
        "\n",
        "        self.image_folder = os.path.join(self.dataset_path,'images')\n",
        "\n",
        "        self.feature_folder_path = os.path.join(self.dataset_path,'feature')\n",
        "        if not os.path.exists(self.feature_folder_path):\n",
        "            os.mkdir(self.feature_folder_path)\n",
        "    def index(self):\n",
        "        print((os.listdir(self.image_folder)))\n",
        "        for img_path in tqdm(os.listdir(self.image_folder)):\n",
        "            #print(\"hello word\")\n",
        "            if img_path==\".ipynb_checkpoints\":\n",
        "              continue\n",
        "            #print(name)\n",
        "            name = img_path.split('/')[-1][:-3]\n",
        "            vector_file = os.path.join(self.feature_folder_path,name+'.pkl')\n",
        "            img_path_full = os.path.join(self.image_folder+'/'+img_path)\n",
        "            #print(img_path_full)\n",
        "            img = cv2.imread(img_path_full)\n",
        "            if self.detector.detect(img) is None:\n",
        "                return 0\n",
        "            x_min, y_min, x_max, y_max = self.detector.detect(img)\n",
        "            PIL_image = Image.open(img_path_full).crop((x_min, y_min, x_max, y_max))\n",
        "            try:\n",
        "                feature_vector = self.extractor.extract(PIL_image)\n",
        "            except:\n",
        "                continue\n",
        "            pickle.dump(feature_vector,open(vector_file,'wb'))\n",
        "    def recognition(self,img):\n",
        "        res_dict={}\n",
        "        \n",
        "        top_similarity=0.0\n",
        "        \n",
        "        for vector_file in os.listdir(self.feature_folder_path):\n",
        "            vector_file_path=os.path.join(self.feature_folder_path,vector_file)\n",
        "            vector=pickle.load(open(vector_file_path,'rb'))\n",
        "            similarity=1-spatial.distance.cosine(vector,self.extractor.extract(img))\n",
        "            name=vector_file.split('.')[0]\n",
        "            temp = {'similary': similarity}\n",
        "            res_dict[name] = temp\n",
        "\n",
        "            if similarity> top_similarity:\n",
        "                top_similarity = similarity\n",
        "                face_name = vector_file.split('.')[0]\n",
        "\n",
        "        if top_similarity < 0.5:\n",
        "            return 'Unknown'\n",
        "\n",
        "        return face_name, top_similarity, res_dict\n",
        "    def recognition_1(self,img,vectors):\n",
        "        res_dict={}\n",
        "        \n",
        "        top_similarity=0.0\n",
        "        i=0\n",
        "        for vector_file in os.listdir(self.feature_folder_path):\n",
        "            #vector_file_path=os.path.join(self.feature_folder_path,vector_file)\n",
        "            \n",
        "            if vector_file==\".ipynb_checkpoints\":\n",
        "              continue\n",
        "            vector=vectors[i]\n",
        "            similarity=1-spatial.distance.cosine(vector,self.extractor.extract(img))\n",
        "            #print(similarity)\n",
        "            #name=vector_file.split('.')[0]\n",
        "            i+=1\n",
        "            if similarity> top_similarity:\n",
        "                face_name = vector_file.split('.')[0]\n",
        "                top_similarity=similarity\n",
        "        if top_similarity < 0.5:\n",
        "            return 'Unknown',0\n",
        "\n",
        "        return face_name,top_similarity    \n",
        "    def recognition_img(self,img_path):\n",
        "        if isinstance(img_path, str):\n",
        "            print(img_path)\n",
        "            PIL_img = Image.open(img_path)\n",
        "            img = cv2.imread(img_path)\n",
        "        x_min,y_min,x_max,y_max=self.detector.detect(img)\n",
        "        process_img=PIL_img.crop((x_min, y_min, x_max, y_max))\n",
        "        bbox_img=cv2.rectangle(img,(x_min,y_min),(x_max,y_max),(0,255,0),2)\n",
        "        if (self.recognition(process_img))[0]=='Unknown':\n",
        "            face_name = \"Unknown\"\n",
        "            cv2.putText(bbox_img, face_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        else:\n",
        "            face_name = (self.recognition(process_img))[0]\n",
        "            cv2.putText(bbox_img, face_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        print(\"chay toi day rui ne\")\n",
        "        cv2_imshow(bbox_img)\n",
        "        #cv2.imwrite('result.jpg', bbox_img)\n",
        "    def recognition_webcam(self):\n",
        "        cap = cv2.VideoCapture(0)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(\"Cannot open webcam\")\n",
        "        vectors=[]\n",
        "        for vector_file in os.listdir(self.feature_folder_path):\n",
        "            vector_file_path=os.path.join(self.feature_folder_path,vector_file)\n",
        "            vector=pickle.load(open(vector_file_path,'rb'))\n",
        "            vectors.append(vector)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if ret is None:\n",
        "                continue\n",
        "\n",
        "            # frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            if self.detector.detect(frame) is None:\n",
        "                continue\n",
        "            \n",
        "\n",
        "            x_min, y_min, x_max, y_max = self.detector.detect(frame)\n",
        "            processed_frame = Image.fromarray(np.uint8(frame[y_min:y_max, x_min:x_max])).convert('RGB')\n",
        "            res_frame = cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "            face,conf=self.recognition_1(processed_frame,vectors)\n",
        "            if face== \"Unknown\":\n",
        "                #face = \"Unknown\"\n",
        "                cv2.putText(res_frame, face, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            else:\n",
        "                #face_name, similarity, _ = self.recognition(processed_frame)\n",
        "                cv2.putText(res_frame, f'{face}: {round(conf)}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            cv2_imshow(res_frame)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "# #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "# system=Facesystem('datasets','VGGFACE')\n",
        "# #system.index()\n",
        "# \n"
      ],
      "metadata": {
        "id": "0ZvDLrgCWasm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system=Facesystem('datasets','VGGFACE')"
      ],
      "metadata": {
        "id": "pI_7hl2eXoHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75b78c1-aec0-4364-b7cd-2f1a18f2e7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
            "58916864/58909280 [==============================] - 1s 0us/step\n",
            "58925056/58909280 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBXfzDC91wHy",
        "outputId": "609c99be-8617-445e-e167-c3da34126b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 23.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system.index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMfNDLPWXtZz",
        "outputId": "b3104fb4-7b28-43d5-88bc-dbc785e5ae88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['khoi.jpg', '.ipynb_checkpoints', 'loc.jpg', 'an.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:11<00:00,  2.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm  -rf .ipynb_checkpoints"
      ],
      "metadata": {
        "id": "QzG5cPCcAmub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"datasets/images\")"
      ],
      "metadata": {
        "id": "nI_n8sstBBjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system.recognition_webcam()"
      ],
      "metadata": {
        "id": "NQiwxz1qX0Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "9e2YfJT3YtKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "s3rLdMIwYucZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  print(filename)\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "FmYA1QYWYuca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "77543d73-4167-41f8-ce9f-405940278374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4cd7f1c45e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-9a3bc4379e3c>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(filename, quality)\u001b[0m\n\u001b[1;32m     36\u001b[0m     ''')\n\u001b[1;32m     37\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhoto({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "8NJsxVpDeYxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "dB_7akHQegYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors=[]\n",
        "for vector_file in os.listdir(system.feature_folder_path):\n",
        "            vector_file_path=os.path.join(system.feature_folder_path,vector_file)\n",
        "            if vector_file_path==\"datasets/feature/.ipynb_checkpoints\":\n",
        "              continue\n",
        "            vector=pickle.load(open(vector_file_path,'rb'))\n",
        "            vectors.append(vector)"
      ],
      "metadata": {
        "id": "i1bYmPTcbdHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors)"
      ],
      "metadata": {
        "id": "RXWm30pQCWWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "from PIL import Image\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "    \n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    #print(img)\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # grayscale image for face detection\n",
        "    point=system.detector.detect(img)\n",
        "    if point is None:\n",
        "          continue\n",
        "\n",
        "    # get face region coordinates\n",
        "    x_min, y_min, x_max, y_max = point[0],point[1],point[2],point[3]\n",
        "    #print(x_min, y_min, x_max, y_max)\n",
        "    processed_frame = Image.fromarray(np.uint8(img[y_min:y_max, x_min:x_max])).convert('RGB')\n",
        "    bbox_array = cv2.rectangle(bbox_array, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "    face,conf=system.recognition_1(processed_frame,vectors)\n",
        "    bbox_array=cv2.putText(bbox_array, face, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "  \n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "r4WbEIwPebDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3f1e1e-143e-4b0e-dcd2-55f79c695382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_min, y_min, x_max, y_max = point[0],point[1],point[2],point[3]\n",
        "    processed_frame = Image.fromarray(np.uint8(img[y_min:y_max, x_min:x_max])).convert('RGB')\n",
        "    res_frame = cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "    face,conf=system.recognition_1(processed_frame,vectors)\n",
        "    if face== \"Unknown\":\n",
        "        #face = \"Unknown\"\n",
        "        cv2.putText(res_frame, face, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    else:\n",
        "        #face_name, similarity, _ = self.recognition(processed_frame)\n",
        "        cv2.putText(res_frame, f'{face}: {round(conf)}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)"
      ],
      "metadata": {
        "id": "E3obgKR_dvi0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}